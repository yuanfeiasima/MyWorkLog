1. 海量数据处理思路
   1. 传统hash 按key哈希， 操作简单但存在单点故障的风险
   2. 一致性hash 原理2^32+1=0
2. 划分

   1. 大数据量--&gt;按数据划分，单机存储千万网页，url为key

   2. 大流量--&gt;按流量划分，按流量划分到机房

   3. 大计算--&gt;按输入数据，划分计算任务，mapReduce（分发计算）

3. 云计算技术难点

   1. 单机系统变为分布式集群系统

   2. 稳定性和容错能力

   3. 数据一致性

   4. 难点：任何消息存在丢失的可能，任何单机存在故障的风险

4. mapReduce--&gt;处理海量数据的分布式计算框架，作用：

   1. 分布式存储 --&gt;HDFS

   2. 作业调度

   3. 容错

   4. 机器间通信

5. 


